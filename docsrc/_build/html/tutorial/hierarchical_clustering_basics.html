<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Hierarchical clustering basics &#8212; CommonNN Clustering  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a5519fdd" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=77a3bc79" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=d18eccf6" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Density-based clustering basics" href="algorithm_explained.html" />
    <link rel="prev" title="Demonstration of (generic) interfaces" href="interface_demo.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }
</style><section id="Hierarchical-clustering-basics">
<h1>Hierarchical clustering basics<a class="headerlink" href="#Hierarchical-clustering-basics" title="Link to this heading">¶</a></h1>
<p>Go to:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#Notebook-configuration"><span class="std std-ref">Notebook configuration</span></a></p></li>
<li><p><a class="reference internal" href="#Dissimilar-blobs-showcase"><span class="std std-ref">Dissimilar blobs showcase</span></a></p>
<ul>
<li><p><a class="reference internal" href="#Parameter-scan"><span class="std std-ref">Parameter scan</span></a></p></li>
<li><p><a class="reference internal" href="#Manual-hierarchical-clustering"><span class="std std-ref">Manual hierarchical clustering</span></a></p></li>
<li><p><a class="reference internal" href="#Label-prediction"><span class="std std-ref">Label prediction</span></a></p></li>
</ul>
</li>
</ul>
<section id="Notebook-configuration">
<h2>Notebook configuration<a class="headerlink" href="#Notebook-configuration" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sklearn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.notebook</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">commonnn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">commonnn</span><span class="w"> </span><span class="kn">import</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">plot</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">commonnn</span><span class="w"> </span><span class="kn">import</span> <span class="n">_fit</span>
</pre></div>
</div>
</div>
<p>Print Python and package version information:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Version information</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Python: &quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Packages:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">package</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mpl</span><span class="p">,</span> <span class="n">np</span><span class="p">,</span> <span class="n">pd</span><span class="p">,</span> <span class="n">sklearn</span><span class="p">,</span> <span class="n">commonnn</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    </span><span class="si">{</span><span class="n">package</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">package</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Python:  3.10.7 (main, Sep 27 2022, 11:41:38) [GCC 10.2.1 20210110]
Packages:
    matplotlib: 3.6.0
    numpy: 1.23.3
    pandas: 1.5.0
    sklearn: 1.1.2
    commonnn: 0.0.2
</pre></div></div>
</div>
<p>We use <a class="reference external" href="https://matplotlib.org/">Matplotlib</a> to create plots. The <code class="docutils literal notranslate"><span class="pre">matplotlibrc</span></code> file in the root directory of the <code class="docutils literal notranslate"><span class="pre">CommonNNClustering</span></code> repository is used to customize the appearance of the plots.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matplotlib configuration</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc_file</span><span class="p">(</span>
    <span class="s2">&quot;../../matplotlibrc&quot;</span><span class="p">,</span>
    <span class="n">use_default_template</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Axis property defaults for the plots</span>
<span class="n">ax_props</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s2">&quot;xlim&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">),</span>
    <span class="s2">&quot;ylim&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">),</span>
    <span class="s2">&quot;xticks&quot;</span><span class="p">:</span> <span class="p">(),</span>
    <span class="s2">&quot;yticks&quot;</span><span class="p">:</span> <span class="p">(),</span>
    <span class="s2">&quot;aspect&quot;</span><span class="p">:</span> <span class="s2">&quot;equal&quot;</span>
<span class="p">}</span>

<span class="c1"># Line plot property defaults</span>
<span class="n">line_props</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;linewidth&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pandas DataFrame print options</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Dissimilar-blobs-showcase">
<h2>Dissimilar blobs showcase<a class="headerlink" href="#Dissimilar-blobs-showcase" title="Link to this heading">¶</a></h2>
<p>Learn in this tutorial how to use the <code class="docutils literal notranslate"><span class="pre">commonnn.cluster</span></code> module for step-wise hierarchical clusterings, where one cluster step does not deliver a satisfactory result. We will also show how to use a data set of reduced size for cluster exploration and how we can transfer the result to the original full size data set.</p>
<p>We will generate a sample data set of three clusters that have very different point densities and are spatially not very well separated. As we will see, it can be non-trivial (if not impossible) to extract all three clusters with a single set of cluster parameters. We will solve the problem by extracting the clusters in a two step procedure. We refer to this kind of hierarchical approach as <em>manual</em> hierarchical clustering.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate blobs with quite different point densities</span>
<span class="n">dblobs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_blobs</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span>
    <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">],</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

<span class="n">dblobs</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dblobs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialise clustering</span>
<span class="n">clustering</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">dblobs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get basic information about the clustering instance</span>
<span class="nb">print</span><span class="p">(</span><span class="n">clustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
alias: &#39;root&#39;
hierarchy_level: 0
access: components
points: 100000
children: 0
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the original data</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
<span class="n">plotted</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">,</span>
    <span class="n">plot_style</span><span class="o">=</span><span class="s2">&quot;contourf&quot;</span><span class="p">,</span>
    <span class="n">plot_props</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;levels&quot;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)}</span>
<span class="p">)</span>

<span class="n">rect</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_position</span><span class="p">()</span><span class="o">.</span><span class="n">bounds</span>
<span class="n">cax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="n">rect</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">rect</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">rect</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.025</span><span class="p">,</span> <span class="n">rect</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">plotted</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=-</span><span class="mi">15</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">((</span><span class="s2">&quot;high&quot;</span><span class="p">,</span> <span class="s2">&quot;low&quot;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$x$&quot;</span><span class="p">,</span> <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$y$&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_16_0.png" src="../_images/tutorial_hierarchical_clustering_basics_16_0.png" />
</div>
</div>
<p>Looking at these 2D plots of the generated points above, we can already tell that this is probably not the easiest of all clustering problems. One of the three clusters is hardly visible when the data points are drawn directly (left plot). More importantly, the point density between the two narrower clusters is as high as the density within the broader cluster (right plot).</p>
<p>We also have generated a fairly large amount of data points. Although we can attempt to cluster the 100,000 points directly, this can be rather slow and memory intensive. For quick data exploration, it might be a good idea to perform the clustering on a reduced data set. We can predict the clustering later for the full sized set on the basis of the reduced result.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reduced_dblobs</span> <span class="o">=</span> <span class="n">dblobs</span><span class="p">[::</span><span class="mi">100</span><span class="p">]</span>
<span class="n">rclustering</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">reduced_dblobs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here, we created a cluster object holding a smaller data set by using a point stride of 100, leaving us with only 1000 points that can be clustered very quickly. By visual inspection, we can now also clearly spot three point clouds.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the reduced data</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">Ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">rclustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
<span class="n">Ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">clustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_input_data</span><span class="o">.</span><span class="n">n_points</span><span class="si">}</span><span class="s2"> points&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">Ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rclustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_input_data</span><span class="o">.</span><span class="n">n_points</span><span class="si">}</span><span class="s2"> points&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;1000 points&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_20_1.png" src="../_images/tutorial_hierarchical_clustering_basics_20_1.png" />
</div>
</div>
<p>When we pre-calculate pairwise point distances, we can plot the distribution of distances. This can give us a very basic estimate for a reasonable radius cutoff as one of the cluster parameters. For globular clusters, each cluster should be visible as a peak in the distance distribution around a value that is very roughly equivalent to the radius of the point cloud. We also expect a peak for each pair of clusters, roughly corresponding to the distance between the cluster centers. For more
complicated data sets this approximation is not valid, but we can still get a feeling for the value range of meaningful radius cutoffs.</p>
<p>In general, we want to pick a rather small radius that allows us to estimate point density with a comparably high resolution. If we pick a too small radius, however, the clustering can become sensitive to (random) fluctuations in the point density which yields probably meaningless clusters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">distances</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">rclustering</span><span class="o">.</span><span class="n">input_data</span><span class="p">)</span>
<span class="n">distance_rclustering</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">recipe</span><span class="o">=</span><span class="s2">&quot;distances&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot</span><span class="o">.</span><span class="n">plot_histogram</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">distances</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">maxima</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">maxima_props</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;order&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_23_0.png" src="../_images/tutorial_hierarchical_clustering_basics_23_0.png" />
</div>
</div>
<p>As a handy rational for a first guess on a suitable radius cutoff, we can use the first maximum in the just plotted distance distribution. For larger numbers of points, the radius can be usually smaller than for poorly sampled data sets. In this particular example, we could start with a radius cutoff of say <span class="math notranslate nohighlight">\(r\approx 0.3\)</span> considering that we have a low number of points in the reduced data set. With this radius fixed, we can than vary the common-nearest-neighbours cutoff <span class="math notranslate nohighlight">\(c\)</span> to tune
the density threshold for the clustering.</p>
<section id="Parameter-scan">
<h3>Parameter scan<a class="headerlink" href="#Parameter-scan" title="Link to this heading">¶</a></h3>
<p>Blindly starting to cluster a data set in a happy-go-lucky attempt may already lead to a satisfactory result in some cases, but let’s tackle this problem in a more systematic way to see how different cluster parameters effect the outcome. A scan of a few parameters shows that it is difficult to extract the three clusters at once with one parameter set. We also apply a member cutoff of 10 to prevent that we obtain clusters that are definitely too small.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="mf">0.3</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">101</span><span class="p">)):</span>
    <span class="c1"># fit from pre-calculated distances</span>
    <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">radius_cutoff</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">similarity_cutoff</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">member_cutoff</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "32dc0ae75b6b4306bcb80a07029d0742", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>Each cluster result will be added to the <code class="docutils literal notranslate"><span class="pre">summary</span></code> attribute of our cluster object.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">distance_rclustering</span><span class="o">.</span><span class="n">summary</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-----------------------------------------------------------------------------------------------
#points   r         nc        min       max       #clusters %largest  %noise    time
1000      0.300     0         10        None      1         0.979     0.021     00:00:0.024
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
#points   r         nc        min       max       #clusters %largest  %noise    time
1000      0.300     1         10        None      1         0.965     0.035     00:00:0.024
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
#points   r         nc        min       max       #clusters %largest  %noise    time
1000      0.300     2         10        None      1         0.950     0.050     00:00:0.024
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
#points   r         nc        min       max       #clusters %largest  %noise    time
1000      0.300     3         10        None      2         0.667     0.065     00:00:0.024
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
#points   r         nc        min       max       #clusters %largest  %noise    time
1000      0.300     4         10        None      3         0.665     0.087     00:00:0.024
-----------------------------------------------------------------------------------------------

</pre></div></div>
</div>
<p>If you have <code class="docutils literal notranslate"><span class="pre">pandas</span></code> installed, you can convert the summary to a nice table as a <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>. This makes the analysis of the cluster results more convenient. We can for example specifically look for clusterings with three obtained clusters and where the largest cluster does not hold much more than a third of the points.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get summary sorted by number of identified clusters</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">to_DataFrame</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;n_clusters&#39;</span><span class="p">)</span>

<span class="c1"># Show cluster results where we have 3 clusters</span>
<span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s2">&quot;radius_cutoff&quot;</span><span class="p">,</span> <span class="s2">&quot;similarity_cutoff&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n_points</th>
      <th>radius_cutoff</th>
      <th>similarity_cutoff</th>
      <th>member_cutoff</th>
      <th>max_clusters</th>
      <th>n_clusters</th>
      <th>ratio_largest</th>
      <th>ratio_noise</th>
      <th>execution_time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>1000</td>
      <td>0.3</td>
      <td>4</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.665</td>
      <td>0.087</td>
      <td>0.023985</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1000</td>
      <td>0.3</td>
      <td>7</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.656</td>
      <td>0.15</td>
      <td>0.024447</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1000</td>
      <td>0.3</td>
      <td>8</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.652</td>
      <td>0.182</td>
      <td>0.02423</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1000</td>
      <td>0.3</td>
      <td>9</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.65</td>
      <td>0.198</td>
      <td>0.024639</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1000</td>
      <td>0.3</td>
      <td>10</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.645</td>
      <td>0.21</td>
      <td>0.024605</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1000</td>
      <td>0.3</td>
      <td>18</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.62</td>
      <td>0.298</td>
      <td>0.026852</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1000</td>
      <td>0.3</td>
      <td>20</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.614</td>
      <td>0.326</td>
      <td>0.02807</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1000</td>
      <td>0.3</td>
      <td>21</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.609</td>
      <td>0.336</td>
      <td>0.02796</td>
    </tr>
    <tr>
      <th>22</th>
      <td>1000</td>
      <td>0.3</td>
      <td>22</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.602</td>
      <td>0.36</td>
      <td>0.028592</td>
    </tr>
    <tr>
      <th>25</th>
      <td>1000</td>
      <td>0.3</td>
      <td>25</td>
      <td>10</td>
      <td>&lt;NA&gt;</td>
      <td>3</td>
      <td>0.341</td>
      <td>0.399</td>
      <td>0.027648</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>The summary shows indeed that we got a clustering with 3 clusters (as desired) for some parameter combinations. Apart from the number of clusters, it is, however often also of interest, how many data points ended up in the clusters and how many are considered outliers (noise). In this case we expect 3 clusters of more or less equal size (member wise) and we may be interested in keeping the outliers-level low. In the results giving 3 clusters, in one case the largest cluster entails one third of
the data points (which is good), but the noise level is around 40 % (which is most likely not what we want). Let’s plot a few results to see what is going on here.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cluster attempts in comparison</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">Ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pair</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">25</span><span class="p">)]):</span>
    <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">radius_cutoff</span><span class="o">=</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">similarity_cutoff</span><span class="o">=</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">member_cutoff</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">record</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">rclustering</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">labels</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">rclustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
    <span class="n">Ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span>
    <span class="n">left</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_33_0.png" src="../_images/tutorial_hierarchical_clustering_basics_33_0.png" />
</div>
</div>
<p>None of the above attempts was able to achieve a split into 3 clusters as we wanted it. One could now try to tinker around with the parameters a bit more (which is probably not very fruitful), or resort to hierarchical clustering. As we see in the plots above (lower right and upper right), two different parameter pairs are leading to splits in different regions of the data, separating either the lowest density cluster from the rest or separating the two denser clusters. So why not apply both of
them, one after the other.</p>
<p>Before we do this let’s have another close look at the cluster results we obtained. Using the <code class="docutils literal notranslate"><span class="pre">summarize</span></code> method of a cluster object, we can visualize a summary table in a 2D contour plot, to evaluate a few quality measures versus the input parameters <em>radius cutoff</em> (<em>r</em>) and <em>similarity criterion</em> (<em>c</em>):</p>
<ul class="simple">
<li><p>number of identified clusters</p></li>
<li><p>members in the largest cluster</p></li>
<li><p>points classified as outliers</p></li>
<li><p>computational time of the fit</p></li>
</ul>
<p>Let’s also throw in a few more different values for the radius cutoff into the mix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">([</span><span class="n">x</span><span class="o">/</span><span class="mi">10</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">101</span><span class="p">):</span>
        <span class="c1"># fit from pre-calculated distances</span>
        <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">radius_cutoff</span><span class="o">=</span><span class="n">r</span><span class="p">,</span>
            <span class="n">similarity_cutoff</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
            <span class="n">member_cutoff</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c9302fb69d664f2793f1a3a0288c8de1", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Computing time</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">summarize</span><span class="p">(</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">quantity</span><span class="o">=</span><span class="s2">&quot;execution_time&quot;</span><span class="p">,</span>
    <span class="n">contour_props</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;levels&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">colorbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">mappable</span><span class="o">=</span><span class="n">contour</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s2">&quot;time / s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_36_0.png" src="../_images/tutorial_hierarchical_clustering_basics_36_0.png" />
</div>
</div>
<p>From the <em>time vs. r/c</em> plot we can see how the total clustering time depends in particular on the neighbour search radius. Larger radii result in larger neighbour lists for each point, increasing the processing time, so if one has the choice, smaller values for <em>r</em> should be preferred.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Noise level</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">summarize</span><span class="p">(</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">quantity</span><span class="o">=</span><span class="s2">&quot;ratio_noise&quot;</span><span class="p">,</span>
    <span class="n">contour_props</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;levels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="o">/</span><span class="mi">100</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">101</span><span class="p">)],</span>
        <span class="p">}</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">colorbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">mappable</span><span class="o">=</span><span class="n">contour</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s2">&quot;noise / %&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_38_0.png" src="../_images/tutorial_hierarchical_clustering_basics_38_0.png" />
</div>
</div>
<p>The ratio of outlier-points depends on the search radius <em>r</em> as well as on the similarity criterion <em>c</em> and increases continuously with the set density threshold. For high density thresholds (low <em>r</em> and high <em>c</em>) the noise ratio is comparably large. The desired amount of noise depends much on the nature of the underlying data set.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Largest cluster</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">summarize</span><span class="p">(</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">quantity</span><span class="o">=</span><span class="s2">&quot;ratio_largest&quot;</span><span class="p">,</span>
    <span class="n">contour_props</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;levels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="o">/</span><span class="mi">100</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">101</span><span class="p">)],</span>
        <span class="p">}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">colorbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">mappable</span><span class="o">=</span><span class="n">contour</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s2">&quot;largest / %&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_40_0.png" src="../_images/tutorial_hierarchical_clustering_basics_40_0.png" />
</div>
</div>
<p>The ratio of points assigned to the largest cluster shows a similar trend as the noise-ratio, only that it changes in a rather step-wise manner. This view could give a good hint towards reasonable parameter combinations if one already has an idea about the expected cluster size. It also shows for which parameters we do not observe any splitting (about 100 % of the points are in the largest cluster).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of clusters</span>
<span class="n">show_n</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">summarize</span><span class="p">(</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">quantity</span><span class="o">=</span><span class="s2">&quot;n_clusters&quot;</span><span class="p">,</span>
    <span class="n">contour_props</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;levels&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">show_n</span> <span class="o">+</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="s2">&quot;vmin&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;vmax&quot;</span><span class="p">:</span> <span class="n">show_n</span><span class="p">,</span>
        <span class="s2">&quot;extend&quot;</span><span class="p">:</span> <span class="s2">&quot;max&quot;</span>
    <span class="p">}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">colorbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">mappable</span><span class="o">=</span><span class="n">contour</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">show_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s2">&quot;# clusters&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_42_0.png" src="../_images/tutorial_hierarchical_clustering_basics_42_0.png" />
</div>
</div>
<p>The probably most telling view is given by the <em>number of clusters</em> plots. The analysis demonstrates nicely that for this data set a splitting into 3 meaningful clusters is hard to achieve. With increased density threshold, the number of obtained clusters does at first increase before it drops again when low density clusters become part of the noise. In general, clusterings that are stable over a wider range of parameter combinations tend to be more meaningful.</p>
</section>
<section id="Manual-hierarchical-clustering">
<h3>Manual hierarchical clustering<a class="headerlink" href="#Manual-hierarchical-clustering" title="Link to this heading">¶</a></h3>
<p>To use the (manual) hierarchical approach on clustering this data set, we will apply a pair of cluster parameters that will extract the lesser dense region of the data as an isolated cluster in a first step. That means we choose a comparably low value for the similarity criterion <em>c</em>. We can refer to these parameters as <em>soft</em> parameters, leaving the more dense regions of the data untouched and in one cluster. Remember that density in terms of common-nearest-neighbour clustering is estimated as
the number of common neighbours within the neighbourhood intersection of two points with respect to a radius <em>r</em>. More common neighbours (higher similarity cutoff <em>c</em>) and/or a smaller neighbourhood radius (smaller <em>r</em>) will result in a higher density requirement. To make this more clear let’s have a look again at some clusterings.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cluster attempts in comparison</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">Ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pair</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)]):</span>
    <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">radius_cutoff</span><span class="o">=</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">similarity_cutoff</span><span class="o">=</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">member_cutoff</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">record</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">rclustering</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">distance_rclustering</span><span class="o">.</span><span class="n">labels</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">rclustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
    <span class="n">Ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span>
    <span class="n">left</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_46_0.png" src="../_images/tutorial_hierarchical_clustering_basics_46_0.png" />
</div>
</div>
<p>For these clusterings, we again keep the radius fixed while we increase the similarity cutoff and therefore the density threshold.</p>
<p><strong>Upper left</strong>: Choosing a low (soft) threshold, results in no cluster splitting. The data set as a whole forms a cluster in which the point density is <em>at least</em> as high as our density requirement.</p>
<p><strong>Upper right</strong>: When we increase the density requirement just a bit, we observe a splitting between the broadly distributed lower density cluster and the more dense clusters. Within both the resulting clusters the point density is higher than required by the parameters but they are separated by a low density region and therefore split. This parameter set can be used for the first step of the hierarchical clustering.</p>
<p><strong>Lower left</strong>: Increasing the density requirement further, eventually leads to a splitting between the two denser clusters. At his point, the broader low density cluster has already vanished into noise because the density within this cluster is lower than the density between the just split denser clusters. We could use this parameter set in a second hierarchical clustering step.</p>
<p><strong>lower right</strong>: Choosing even harder parameters leaves only the densest cluster. The second densest cluster falls into the noise region.</p>
<p>The central element of the manual hierarchical cluster functionality is the <code class="docutils literal notranslate"><span class="pre">isolate</span></code> method of a <code class="docutils literal notranslate"><span class="pre">Clustering</span></code> object. After a clustering (with soft parameters) we can <em>freeze</em> the result before we start to re-cluster.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># After the first step, we need to isolate the cluster result</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">radius_cutoff</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">similarity_cutoff</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">member_cutoff</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">record</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">isolate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">isolate</span></code> method will create a new <code class="docutils literal notranslate"><span class="pre">Bundle</span></code> object (a child) for every cluster of a cluster result. In our case we get two new child clusters (plus one for outliers). The clusters are stored in a dictionary under the <code class="docutils literal notranslate"><span class="pre">children</span></code> attribute of the parent <code class="docutils literal notranslate"><span class="pre">Bundle</span></code> object. The children dictionary of the root data after isolation holds a <code class="docutils literal notranslate"><span class="pre">Bundle</span></code> object for each cluster found in the last step.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">alias</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">rclustering</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{1: &#39;root.1&#39;, 2: &#39;root.2&#39;}
</pre></div></div>
</div>
<p>When we access the chidren dictionary from our <code class="docutils literal notranslate"><span class="pre">Clustering</span></code> object, we are actually looking at the children of the respective root bundle.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rclustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">children</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{1: Bundle(alias=&#39;root.1&#39;, hierarchy_level=1),
 2: Bundle(alias=&#39;root.2&#39;, hierarchy_level=1)}
</pre></div></div>
</div>
<p>Since we will use different cluster parameters now for different clusters it would be nice to have something to keep the overview of which cluster has been identified under which parameters. This information is provided by the <code class="docutils literal notranslate"><span class="pre">meta</span></code> attribute on the object that stores the cluster label assignments on the <code class="docutils literal notranslate"><span class="pre">Bundle</span></code> which we get with <code class="docutils literal notranslate"><span class="pre">Bundle._labels</span></code>. Note that this is different to <code class="docutils literal notranslate"><span class="pre">Clustering.labels</span></code> which only return the actual labels in form of a NumPy array. The label meta information
tells us three things:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">origin</span></code>: How have these labels been assigned? The entry <code class="docutils literal notranslate"><span class="pre">&quot;fit&quot;</span></code> means, they were obtained by a regular clustering.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reference</span></code>: This is a related clustering object, i.e. the object that is associated to the data for which the labels are valid. For <code class="docutils literal notranslate"><span class="pre">&quot;fitted&quot;</span></code> labels this is a reference to the bundle object itself that carries the labels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code>: This is a dictionary stating the cluster parameters (<em>r</em>, <em>c</em>) that led to each cluster. For <code class="docutils literal notranslate"><span class="pre">&quot;fitted&quot;</span></code> labels, each cluster has the same parameters.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">!r}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">rclustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_labels</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
params: {1: (0.3, 3), 2: (0.3, 3)}
reference: &lt;weakproxy at 0x7fa08182df30 to commonnn._bundle.Bundle at 0x7fa08d0928c0&gt;
origin: &#39;fit&#39;
</pre></div></div>
</div>
<p>Every single isolated child bundle is represented by a full-fledged, completely functional <code class="docutils literal notranslate"><span class="pre">Bundle</span></code> object itself. When we want to re-cluster a child, this is no different to clustering a parent.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">child1</span> <span class="o">=</span> <span class="n">rclustering</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># rclustering.children[1]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">child1</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>  <span class="c1"># Child cluster 1</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
alias: &#39;root.1&#39;
hierarchy_level: 1
access: components
points: 667
children: 0
</pre></div></div>
</div>
<p>Note, that the <code class="docutils literal notranslate"><span class="pre">hierarchy_level</span></code> in the above overview has increased to 1. We can again plot the distance distribution within this child cluster to see how this changed.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">distances_child1</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">child1</span><span class="o">.</span><span class="n">input_data</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot</span><span class="o">.</span><span class="n">plot_histogram</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">distances_child1</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">maxima</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">maxima_props</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;order&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_59_0.png" src="../_images/tutorial_hierarchical_clustering_basics_59_0.png" />
</div>
</div>
<p>And then we can attempt the second clustering step. Note that we need to pass the child bundle to the fit function as the first argument (or the <code class="docutils literal notranslate"><span class="pre">bundle</span></code> keyword argument).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now cluster the child cluster</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">child1</span><span class="p">,</span>  <span class="c1"># bundle</span>
    <span class="n">radius_cutoff</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">similarity_cutoff</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">member_cutoff</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">rclustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">,</span> <span class="n">bundle</span><span class="o">=</span><span class="n">child1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-----------------------------------------------------------------------------------------------
#points   r         nc        min       max       #clusters %largest  %noise    time
667       0.300     30        10        None      2         0.505     0.153     00:00:0.032
-----------------------------------------------------------------------------------------------

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_61_1.png" src="../_images/tutorial_hierarchical_clustering_basics_61_1.png" />
</div>
</div>
<p>As a little extra feature a <code class="docutils literal notranslate"><span class="pre">Clustering</span></code> object has a <code class="docutils literal notranslate"><span class="pre">pie</span></code> method that allows to visualize the current state and splitting on the different hierarchy levels as a pie-diagram (from level 0 in the middle to lower levels to the outside).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The cluster hierarchy can be visualised as pie diagram</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">pie</span><span class="p">(</span>
    <span class="n">pie_props</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;radius&quot;</span><span class="p">:</span> <span class="mf">0.15</span><span class="p">,</span>
        <span class="s2">&quot;wedgeprops&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(-0.3, 0.3)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_63_1.png" src="../_images/tutorial_hierarchical_clustering_basics_63_1.png" />
</div>
</div>
<p>Alternatively, a hierarchical tree can be drawn using the <code class="docutils literal notranslate"><span class="pre">tree</span></code> method.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tree shows only isolated bundles</span>
<span class="n">child1</span><span class="o">.</span><span class="n">isolate</span><span class="p">()</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">tree</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_65_0.png" src="../_images/tutorial_hierarchical_clustering_basics_65_0.png" />
</div>
</div>
<p>Now that we have isolated one cluster in the first step and two others in a further splitting on a lower hierarchy level, the last step that remains, is to put everything back together. This can be done automatically by calling <code class="docutils literal notranslate"><span class="pre">reel</span></code> on the parent cluster object into which the child cluster results should be integrated.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wrap up the hierarchical clustering and integrate the child clusters into</span>
<span class="c1">#   the parent cluster</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">reel</span><span class="p">()</span>

<span class="c1"># Manually sort clusters by size (make largest be cluster number 1)</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_labels</span><span class="o">.</span><span class="n">sort_by_size</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Remove children</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">pie</span><span class="p">(</span>
    <span class="n">pie_props</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;radius&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
        <span class="s2">&quot;wedgeprops&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(-0.3, 0.3)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_68_1.png" src="../_images/tutorial_hierarchical_clustering_basics_68_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">rclustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_69_0.png" src="../_images/tutorial_hierarchical_clustering_basics_69_0.png" />
</div>
</div>
</section>
<section id="Label-prediction">
<h3>Label prediction<a class="headerlink" href="#Label-prediction" title="Link to this heading">¶</a></h3>
<p>Now, the parameter information saved for the labels becomes even more useful as they differ for the clusters from different clustering steps.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rclustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_labels</span><span class="o">.</span><span class="n">meta</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;params&#39;: {2: (0.3, 3), 3: (0.3, 30), 1: (0.3, 30)},
 &#39;reference&#39;: &lt;weakproxy at 0x7fa08182df30 to commonnn._bundle.Bundle at 0x7fa08d0928c0&gt;,
 &#39;origin&#39;: &#39;reel&#39;}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">rclustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_labels</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Label   r       c
--------------------
1       0.3     30
2       0.3     3
3       0.3     30
</pre></div></div>
</div>
<p>The cluster result is satisfying. But we have clustered only a reduced set of 1000 points. We would like to predict the cluster label assignment for the full 100,000 points on the basis of the reduced set assignments. This we can do with the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method of a cluster object. We call <code class="docutils literal notranslate"><span class="pre">predict</span></code> with another cluster object for which labels should be predicted as an argument. Similar to a regular <code class="docutils literal notranslate"><span class="pre">fit</span></code> we need to compute neighbourhoods for the points that need assignment, but this time we
need relative neighbourhoods between two data sets. We want to compute the neighbouring points in the small set <code class="docutils literal notranslate"><span class="pre">rclustering</span></code> for the points in the big set <code class="docutils literal notranslate"><span class="pre">clustering</span></code>. When we predict labels we should do the prediction separately for the clusters because the assignment parameters differ. This is where the label info comes in handy showing us the parameters used for the fit as an orientation.</p>
<div class="admonition note">
<p><strong>Info:</strong> A cluster label prediction requires a <code class="docutils literal notranslate"><span class="pre">Predictor</span></code> in the same way as a clustering requires a <code class="docutils literal notranslate"><span class="pre">Fitter</span></code>. See tutorial <a class="reference internal" href="advanced_usage.html"><span class="doc">Advanced usage</span></a> for details.</p>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rclustering</span><span class="o">.</span><span class="n">_predictor</span> <span class="o">=</span> <span class="n">_fit</span><span class="o">.</span><span class="n">PredictorCommonNNFirstmatch</span><span class="p">(</span>
    <span class="n">rclustering</span><span class="o">.</span><span class="n">_fitter</span><span class="o">.</span><span class="n">_neighbours_getter</span><span class="p">,</span>
    <span class="n">clustering</span><span class="o">.</span><span class="n">_fitter</span><span class="o">.</span><span class="n">_neighbours_getter</span><span class="p">,</span>
    <span class="n">rclustering</span><span class="o">.</span><span class="n">_fitter</span><span class="o">.</span><span class="n">_neighbours</span><span class="p">,</span>
    <span class="n">rclustering</span><span class="o">.</span><span class="n">_fitter</span><span class="o">.</span><span class="n">_neighbour_neighbours</span><span class="p">,</span>
    <span class="n">rclustering</span><span class="o">.</span><span class="n">_fitter</span><span class="o">.</span><span class="n">_similarity_checker</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">Ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">r</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">;</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">clustering</span><span class="o">.</span><span class="n">root</span><span class="p">,</span>
    <span class="n">radius_cutoff</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">similarity_cutoff</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
    <span class="n">clusters</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">purge</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
<span class="n">Ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;1 </span><span class="si">{</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">r</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">;</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">clustering</span><span class="o">.</span><span class="n">root</span><span class="p">,</span>
    <span class="n">radius_cutoff</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">similarity_cutoff</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
    <span class="n">clusters</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">purge</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
<span class="n">Ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;2 </span><span class="si">{</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">r</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">;</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">rclustering</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">clustering</span><span class="o">.</span><span class="n">root</span><span class="p">,</span>
    <span class="n">radius_cutoff</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">similarity_cutoff</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
    <span class="n">clusters</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">purge</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">ax_props</span><span class="o">=</span><span class="n">ax_props</span><span class="p">)</span>
<span class="n">Ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;3 </span><span class="si">{</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;3 (0.3, 30)&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_hierarchical_clustering_basics_76_1.png" src="../_images/tutorial_hierarchical_clustering_basics_76_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">clustering</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">_labels</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Label   r       c
--------------------
1       0.3     30
2       0.3     3
3       0.3     30
</pre></div></div>
</div>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">CommonNN Clustering</a></h1>



<p class="blurb">A Python package for common-nearest-neighbour clustering</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=bkellerlab&repo=CommonNNClustering&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../_source/install.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_source/quickstart.html">Quickstart</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../_source/tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="basic_usage.html">Basic usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="scikit_learn_datasets.html">Clustering of scikit-learn toy data sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="advanced_usage.html">Advanced usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="interface_demo.html">Demonstration of (generic) interfaces</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Hierarchical clustering basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="algorithm_explained.html">Density-based clustering basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="md_example.html">Molecular dynamics application example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../_source/api_reference.html">API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../_source/tutorials.html">Tutorials</a><ul>
      <li>Previous: <a href="interface_demo.html" title="previous chapter">Demonstration of (generic) interfaces</a></li>
      <li>Next: <a href="algorithm_explained.html" title="next chapter">Density-based clustering basics</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2022, Jan-Oliver Kapp-Joswig.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../_sources/tutorial/hierarchical_clustering_basics.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>